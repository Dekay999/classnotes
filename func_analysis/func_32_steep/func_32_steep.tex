\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
En Dik Inis (Steepest Descent)

Daha önce gradyan iniþi konusunda iþlediðimiz üzere bir $f$ fonksiyonu için
hesaplanan $-\nabla f(x)$ gradyaný $x$ noktasýnda fonksiyon için en yüksek
iniþ (descent) olacak yönü gösterir. Dikkat, {\em yön} kelimesini
kullandýk, o yönde ne kadar adým atýlacaðýný belirtmedik. Gradyanýn temel
hesabý türeve dayalý olduðu için ve türev hesapladýðý noktaya yakýn bir
yerde doðru bir yaklaþýklama olacaðý için o yönde atýlan adýmýn büyüklüðüne
göre minimizasyon doðru ya da yanlýþ yöne gidiyor olabilir. Bu sebeple
gradyan iniþi algoritmalarý, ki

$$
x^{x+1} = x^k + \alpha_k \nabla f(x^k)
$$

ile kodlanýrlar, çoðunlukla pek çok ufak adým atarlar, yani $\alpha_k$
sabitleri ufak seçilir.

En Dik Ýniþ algoritmasi bu noktada bir ilerleme saðlar. Her $\alpha$, yani
$\alpha_k$ öyle seçilir ki $\phi(\alpha) \equiv f(x^k - \alpha \nabla f(x^k))$
minimize edilsin. Ya da 

$$
\alpha_k = \arg\min_{\alpha \ge 0} f(x^k - \alpha \nabla f(x^k))
$$

Yani gradyanýn iþaret ettiði yönde bir tür ``arama'' yapmýþ oluyoruz, adým
büyüklüðünü öyle seçiyoruz ki fonksiyon o yönde o kadar adým atýldýðýnda en
fazla iniþi gerçekleþtirmiþ olsun. 

Arama derken akla ikinci bir dongu icinde yine ufak ufak adimlar atarak
adim buyukluk hesabi yapmak geliyor, bu kabaca dogru, ama bize yardimci
olacak bazi cebirsel numaralar var. 
















[devam edecek]

Kaynaklar 

[1] Zak, {\em An Introduction to Optimization, 4th Edition}



\end{document}
