\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Özkodlama (Autoencoding)

Özkodlamanýn yaptýðýnýn bir tür "veriyi sýkýþtýrma" iþlemi
söylenebilir. Yapay öðrenmede algoritmalarýn denetimli ve denetimsiz
olarak ikiye ayrýldýðýndan bahsetmiþtik, özkodlama denetimsiz çalýþýr
yani ortada etiket yoktur, daha doðrusu özkodlama verinin kendisini
etiket olarak kullanýr.

\includegraphics[width=30em]{autoenc_02.png}

Yani girdi olarak verilen veriyi çýktý olarak ta kullanýrsak, YSA'yý
kendi çýktýsýný tekrar oluþturmayý öðrenmeye zorlamýþ oluruz, bu
YSA'yý veriyi özetlemeye doðru yöneltecektir, ve bu tekrar oluþturma
için ileri besleme sýrasýnda veriyi dar bir noktadan geçmeye zorlarsak
(üstteki resimde görülüyor, 7 nöronluk girdi 5 nöronluk "daha dar" bir
katmandan geçmeye zorlanýyor), bu YSA'yý "sýkýþtýrma" yapmaya daha da
meyýllendirecektir.

\inputminted[fontsize=\footnotesize]{python}{mnist_autoenc.py}

\begin{minted}[fontsize=\footnotesize]{python}
from keras.datasets import mnist
import mnist_autoenc

(x_train, _), (x_test, _) = mnist.load_data()
x_test = x_test.astype('float32') / 255.
autoencoder, encoder, decoder = mnist_autoenc.get_model()
encoder.load_weights("mod-enc-1.h5")
decoder.load_weights("mod-dec-1.h5")
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
tmp = x_test[1090, :, :].reshape(1,28*28)
encoded = encoder.predict(tmp)
print (encoded.shape)
decoded = decoder.predict(encoded).reshape(28,28)
print (decoded.shape)
plt.imshow(decoded)
plt.gray()
plt.savefig('autoenc_01.png')
\end{minted}

\includegraphics[width=20em]{autoenc_01.png}

\inputminted[fontsize=\footnotesize]{python}{mnist_autoenc_rnn_simple.py}

\begin{minted}[fontsize=\footnotesize]{python}
import mnist_autoenc_rnn_simple

seq_autoencoder, encoder = mnist_autoenc_rnn_simple.get_model()
seq_autoencoder.load_weights("mod-rnn-autoenc-sim.h5")
encoder.load_weights("mod-rnn-enc-sim.h5")
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
decoded = seq_autoencoder.predict(tmp).reshape(28,28)
print (decoded.shape)
plt.imshow(decoded)
plt.gray()
plt.savefig('autoenc_03.png')
\end{minted}

\includegraphics[width=20em]{autoenc_03.png}

Varyasyonel Özkodlayýcýlar

Standard özkodlayýcýlarýn bir problemi kodlama yaptýklarý daralmýþ
alandaki vektörlerin sürekli olmayabileceði, ve buradaki deðerlerin
kolay bir þekilde interpolasyon yapýlmasýndaki bazý zorluklar.

\includegraphics[width=40em]{autoenc_06.png}

\includegraphics[width=20em]{autoenc_07.png}

\inputminted[fontsize=\footnotesize]{python}{mnist_lstm_vae.py}

\begin{minted}[fontsize=\footnotesize]{python}
import mnist_lstm_vae

vae, enc, gen = mnist_lstm_vae.create_lstm_vae(mnist_lstm_vae.input_dim, 
    timesteps=mnist_lstm_vae.timesteps, 
    batch_size=mnist_lstm_vae.batch_size, 
    intermediate_dim=mnist_lstm_vae.latent_dim,
    latent_dim=mnist_lstm_vae.latent_dim,
    epsilon_std=1.)
vae.load_weights('mnist_lstm_vae.h5')
enc.load_weights('mnist_lstm_enc.h5')
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
import random
idx = 400
print (tmp.shape)
x_test_tmp = x_test[idx]
res = vae.predict(x_test_tmp.reshape((1, 28, 28)))

plt.figure()
ax = plt.subplot(1, 2, 1)
pixels = res.reshape((28, 28))
plt.imshow(pixels)
plt.gray()
ax = plt.subplot(1, 2, 2)
plt.imshow(x_test_tmp)
plt.gray()

plt.savefig('autoenc_04.png')
\end{minted}

\includegraphics[width=20em]{autoenc_04.png}

\inputminted[fontsize=\footnotesize]{python}{aae_normal.py}

\inputminted[fontsize=\footnotesize]{python}{aae_lstm.py}

\begin{minted}[fontsize=\footnotesize]{python}
import aae_normal
latent_dim = 100
input_shape = (28, 28)
encoder = aae_normal.model_encoder(latent_dim, input_shape)
encoder.load_weights('aae-norm-encoder.h5')
generator = aae_normal.model_generator(latent_dim, input_shape)
generator.load_weights('aae-norm-generator.h5')
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
idx = 100
print (x_test[idx, :].shape)
res = encoder.predict(x_test[idx, :].reshape(1,28,28))
print (res.shape)
pixels = generator.predict(res)
pixels = pixels.reshape((28, 28))
plt.imshow(pixels)
plt.gray()
plt.savefig('autoenc_05.png')
\end{minted}

\includegraphics[width=20em]{autoenc_05.png}



Kaynaklar

[1] \url{https://blog.keras.io/building-autoencoders-in-keras.html}

[2] adverserial autoencoder keras \url{https://github.com/bstriner/keras-adversarial/blob/master/examples/example_aae.py}

[3] \url{https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf}

[4] \url{https://hsaghir.github.io/data_science/denoising-vs-variational-autoencoder/}

[5] Doersch, Tutorial on Variational Autoencoders, \url{https://arxiv.org/pdf/1606.05908.pdf}

[6] Goodfellow, Adversarial Autoencoders, \url{https://arxiv.org/pdf/1511.05644.pdf}

[7] What is Adversarial Autoencoder?, \url{https://www.quora.com/What-is-Adversarial-Autoencoder}

[8] \url{http://www.inference.vc/adversarial-autoencoders/}


\end{document}
