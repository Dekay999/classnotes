\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Optik Karakter Tanýma, Yazý Tanýma (Optical Character Recognition -OCR-)

OCR, iki dizini birbiriyle uyuþturma problemi olarak görülebilir. Dizi
derken neden bahsetmek istediðimi anlatmaya uðrasayým. Çoðunlukla tanýmak
istediðimiz görüntü bir kelime, bir sayý dizisidir, ve bu dizi ufak ya da
büyük bir kelime olabilir. Girdi ise boyutlarý önceden tanýmlanan görüntüyü
temsil eden veri parçalarý olacaktýr, bu görüntü bir kelimeye
odaklanabilir, görüntü aktarýlmadan önce o kelime bir kare içine alýnmaya
çalýþýr.

Kelime görüntüsünü bir evriþim tabakasý üzerinden mesela iþlenmiþ veriler
olarak parça parça, kesitler olarak alabiliriz. Ardýndan veri parçalarýnýn
zamansal ilintilerini yakalayabilmek için onlarý bir LSTM katmanýna
verebiliriz, ve her zaman adýmýndaki alfabe boyutundaki çýktýlar, bir
vektör olarak, her hücrede belli bir harfin olma olasýlýðý olarak
ayarlanabilir. Eðer en son katmandan sonra uygun bir hata fonksiyonu
tanýmlayabilirsek bilinen etiketli kelimeler, onlarýn görüntüsünü içeren
eðitim verisi üzerinden tüm bu yapýyý eðitebiliriz.

\includegraphics[width=30em]{ocr_01.png}

Üstteki figürde Ýngilizce apple (elma) kelimesini görüyoruz. Girdi görüntü
(input image) geniþliði 128, yüksekliði 64 ve üç kanal var, bu kanallar her
renk için R,G,B olabilir. Ýlk önce evriþimsel sinir aðý özellik çýkartma
(CNN feature extraction) katmaný ile özellik bulmaya uðraþýlýyor, buradan
(4,8,4) boyutunda bir tensor elde ediliyor. Bu tensor (16,8) boyutuna
getiriliyor, bu yeni tensor'daki her kolon (biri yeþille iþaretli) önceki
tensorda bir parçaya tekabül eder, yani kelime görüntüsünün bir parçasýna.

Ardýndan þekillendirme (reshape) sonrasý alýnan yeni tensoru parça parça
LSTM tabakasýna veriyoruz, ilk LSTM hücresi mesela alttaki gibi,

\includegraphics[width=30em]{ocr_02.png}

LSTM sonrasý tamamen baðlanmýþ (fully-connected) tabaka ve softmax ile
alfabe tahmini üretiliyor. Bu örnekte alfabede 6 karakter var, bu sebeple
vektör (6,1) boyutlu, karakterler 'a','e','l','p','z','-'. En son '-'
karakteri ``boþ karakter'' demek, boþ karakterin niye lazým olduðunu
göreceðiz. Vektördeki ilk hücre $y_a^1$ yani 'a', o noktada 'a'
karakterinin olma olasýlýðý. Diðerleri o birinci hücre için aþaðý doðru
$y_e^1$, $y_l^1$, vs. diye devam edecek. Þimdi tüm LSTM hücrelerini iceren
resme bakalým,

\includegraphics[width=35em]{ocr_03.png}

Þimdi elimizde 8 tane 6 boyutlu softmax vektörü var. 

Bu noktada iki sorumuz var: ilki YSA eðitimi baðlamýnda nasýl bir kayýp
fonksiyonu bulalým ki uyan kelimeler için az, kötü uyanlar için yüksek
rakam üretsin, ikincisi farklý boyutlardaki iki vektörün birbirine uymasý
ne demektir? Tüm bunlar tabii ki üstteki softmax vektörlerini nasýl dekode
edip bir kelime üretiriz sorusu ile yakýn alakalý.

Uyum konusu önemli çünkü el yazýsý, ya da font seçimi dolasýyla bazý
karakterler diðerlerinden daha fazla yer tutuyor olabilir. Ayný þey ses
tanýma için de geçerli, ``merhaba'' derken kimisi ``meeeerhaba'' demiþ
olabilir, burada 'e' harfinden daha fazla ses verisi alýnacaktýr, ama o
noktada üzerinde olunan harf deðiþmemiþtir.

Dekode için akla gelebilecek ilk yaklaþým her vektör için en yüksek
olasýlýktaki hücreye tekabül eden karakteri seçmek (find the most probable
symbol), sonra bir ek iþlem tabakasýna giderek bazý elemeler, düzeltmeler
yaparak bir kelimeye eriþmeye uðraþmak. Mesela en olasýlý karakter seçimi
sonrasý arka arka gelen tekrar eden harfleri çýkartýrýz, sonra boþ
karakteri çýkartýrýz,

\includegraphics[width=37em]{ocr_04.png}

Tüm bunlar oldukca basit görünüyor. Fakat tüm bu iþlemleri bir kayýp
fonksiyonu olarak kullanmak istersek iþler karýþýyor. Çünkü kelime bulmaya
uðraþýrken softmax'lerde baþlangýçtan sona pek çok farklý gidiþ yolu var,
tüm kombinasyonlarý iþlemek zor.

\includegraphics[width=37em]{ocr_05.png}

Ayrýca üstteki kýsaltma algoritmasý en iyi sonucu da her zaman
vermeyebilir. Kombinasyon derken üstteki örnek için bile $6^8 = 1,679,616$
tane seçenekten bahediyoruz. Daha büyük bir sözlük, ve daha fazla LSTM
adýmý için bu sayý astronomik boyutlara varabilir.

Çözüm nedir? Seçenekler arasýndan uygun yolu bulup hesaplayan, ya da verili
bir etiket için olurluk (likelihood) hesabý yapan bir yaklaþým var, buna
baðlantýsal zamansal bedel (connectionist temporal cost) adý veriliyor,
detaylar için [1,2,3]. CTC dinamik programlama kullanýr, ayrýca yolu
hesaplarken Gizli Markod Modellerine benzer $\alpha,\beta$ fonksiyonlarý
yaratýr, ve YSA öðrenimi baðlamýnda bu fonksiyonlar üzerinden gradyan
hesabý mümkün oluyor, ve farklý boyuttaki girdi / çýktý arasýndaki uyuþma,
eðitim iþte bu þekilde yapýlýyor.

TensorFlow ile CTC

TF ile CTC hesabýný görelim. Alttaki çýktýnýn daha önce þemasýný verdiðimiz
YSA'ya benzer bir yapýnýn son adýmýndan çýkan softmax olasýlýklarý olduðunu
düþünelim. Verinin satýrlarý her LSTM adýmý, her kolon alfabedeki farklý
bir karakter. 

\begin{minted}[fontsize=\footnotesize]{python}
train_inputs_0 = np.asarray(
    [[0.633766, 0.221185, 0.0917319, 0.0129757, 0.0142857, 0.0260553],
     [0.111121, 0.588392, 0.278779, 0.0055756, 0.00569609, 0.010436],
     [0.0357786, 0.633813, 0.321418, 0.00249248, 0.00272882, 0.0037688],
     [0.0663296, 0.643849, 0.280111, 0.00283995, 0.0035545, 0.00331533],
     [0.458235, 0.396634, 0.123377, 0.00648837, 0.00903441, 0.00623107]],
    dtype=np.float32)
\end{minted}

Bu yapý üzerinde için mesela \verb![0, 1, 2, 1, 0]! dizisini kontrol
etmemiz istense dizinin kaybý / hatasý nedir?

\begin{minted}[fontsize=\footnotesize]{python}
import tensorflow as tf

def sparse_tuple_from(sequences, dtype=np.int32):
    indices = []
    values = []
    for n, seq in enumerate(sequences):
        indices.extend(zip([n] * len(seq), range(len(seq))))
        values.extend(seq)
    indices = np.asarray(indices, dtype=np.int64)
    values = np.asarray(values, dtype=dtype)
    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1] + 1], dtype=np.int64)
    return indices, values, shape

train_seq_len = [5]
num_features = 6

tf.reset_default_graph()

targets = tf.sparse_placeholder(tf.int32)
logits1 = tf.placeholder(tf.float32, [None, num_features] )
logits2 = tf.reshape(logits1, [1, -1, num_features])
logits3 = tf.transpose(logits2, (1, 0, 2))
seq_len = tf.placeholder(tf.int32, [None])
loss = tf.nn.ctc_loss(targets, logits3, seq_len)
decoded, log_prob = tf.nn.ctc_greedy_decoder(logits3, seq_len)

with tf.Session() as sess:

     sess.run(tf.global_variables_initializer())

     train_targets = sparse_tuple_from([[0, 1, 2, 1, 0]])     
     feed_t = { logits1: train_inputs_0, 
                targets: train_targets, 
                seq_len: train_seq_len }
     res = sess.run(loss, feed_t)     
     print u'kayýp', res
\end{minted}

\begin{verbatim}
kayýp [ 7.27719784]
\end{verbatim}

Farklý veri, farklý çýktý,

\begin{minted}[fontsize=\footnotesize]{python}
train_inputs_1 = np.asarray(
    [[0.30176, 0.28562, 0.0831517, 0.0862751, 0.0816851, 0.161508],
     [0.24082, 0.397533, 0.0557226, 0.0546814, 0.0557528, 0.19549],
     [0.230246, 0.450868, 0.0389607, 0.038309, 0.0391602, 0.202456],
     [0.280884, 0.429522, 0.0326593, 0.0339046, 0.0326856, 0.190345],
     [0.423286, 0.315517, 0.0338439, 0.0393744, 0.0339315, 0.154046]],
    dtype=np.float32)

with tf.Session() as sess:

     sess.run(tf.global_variables_initializer())

     train_targets = sparse_tuple_from([[0, 1, 1, 0]])     
     feed_t = { logits1: train_inputs_1, 
                targets: train_targets, 
                seq_len: train_seq_len }
     res = sess.run(loss, feed_t)     
     print u'kayýp', res
\end{minted}

\begin{verbatim}
kayýp [ 8.08572388]
\end{verbatim}

Þimdi ilginç bir veri, burada veri direk 2. karakter olsun diyor. O zaman
buna uyan çýktýlar yüksek, uymayanlar alçak sonuç vermeli,

\begin{minted}[fontsize=\footnotesize]{python}
train_inputs_2 = np.asarray(
    [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]],
    dtype=np.float32)

with tf.Session() as sess:

     sess.run(tf.global_variables_initializer())

     train_targets = sparse_tuple_from([[2, 2, 2]]) 
     feed_t = { logits1: train_inputs_2, 
                targets: train_targets, 
                seq_len: train_seq_len }
     res = sess.run(loss, feed_t)     
     print u'kayýp', res

     train_targets = sparse_tuple_from([[0, 1, 1, 0]]) 
     feed_t = { logits1: train_inputs_2, 
                targets: train_targets, 
                seq_len: train_seq_len }
     res = sess.run(loss, feed_t)     
     print u'kayýp', res
\end{minted}

\begin{verbatim}
kayýp [ 7.21795845]
kayýp [ 10.21795845]
\end{verbatim}

Dekode

TF CTC ile dekode iþlemi de yapýlabilir,

\begin{minted}[fontsize=\footnotesize]{python}        
with tf.Session() as sess:

     sess.run(tf.global_variables_initializer())

     feed_dec = { logits1: train_inputs_0, seq_len: train_seq_len }
     decoded_res = sess.run(decoded, feed_dec)     
     print 'dekode', decoded_res
     
     feed_dec = { logits1: train_inputs_1, seq_len: train_seq_len }
     decoded_res = sess.run(decoded, feed_dec)     
     print 'dekode', decoded_res
     
     feed_dec = { logits1: train_inputs_2, seq_len: train_seq_len }
     decoded_res = sess.run(decoded, feed_dec)     
     print 'dekode', decoded_res
\end{minted}

\begin{verbatim}
dekode [SparseTensorValue(indices=array([[0, 0],
       [0, 1],
       [0, 2]]), values=array([0, 1, 0]), dense_shape=array([1, 3]))]
dekode [SparseTensorValue(indices=array([[0, 0],
       [0, 1],
       [0, 2]]), values=array([0, 1, 0]), dense_shape=array([1, 3]))]
dekode [SparseTensorValue(indices=array([[0, 0]]), values=array([2]), dense_shape=array([1, 1]))]
\end{verbatim}

En son örnekte \verb!values=array([2])! sonucu geldi, yani dekode iþlemi
doðru bir þekilde tüm adýmlar için tek bir seçim olan 2 seçimini yaptý. Bu
seçim arka arkaya tekrarlanmýþ olacaktý tabii ki bu sebeple bir kez
gösteriliyor, appleeee yerine apple demek gibi.

[devam edecek]




Kaynaklar

[1] Graves, {\em Supervised Sequence Labelling with Recurrent Neural Networks}, \url{https://www.cs.toronto.edu/~graves/preprint.pdf}

[2] Graves, {\em How to build a recognition system (Part 2): CTC Loss}, \url{https://docs.google.com/presentation/d/12gYcPft9_4cxk2AD6Z6ZlJNa3wvZCW1ms31nhq51vMk}

[3] Graves, {\em How to build a recognition system (Part 1): CTC Loss}, \url{https://docs.google.com/presentation/d/1AyLOecmW1k9cIbfexOT3dwoUU-Uu5UqlJZ0w3cxilkI}


\end{document}
