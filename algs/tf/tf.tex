\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Tensorflow (TF)

Google'ýn yazdýðý ve açýk yazýlým haline getirdiði paket TF çoðunlukla
yapay öðrenim baðlamýnda gündeme geliyor, fakat TF aslýnda genel kullanýmý
olan bir paket. TF bir sayýsal hesap kütüphanesi, daha spesifik olarak, ona
çizit olarak verilen hesaplarý yapabilen bir sayýsal hesap paketi.

TF ile hesap yapmak için hesabý temsil eden bir çizit kurulur, mesela
$f(x,y) = x^2y + y + 2$ için

\includegraphics[width=20em]{tf_01.png}

Bu hesap aðaçýnda görülen sayýlar tek sayý olabilir, çok boyutlu vektör,
matris, ya da çok boyutlu matris olabilir. Matematikte bu objelere genel
olarak ``tensor'' ismi veriliyor, paketin ismi de buradan geliyor,
tensorlar hesap çiziti içinde bir hesaptan diðerine ``akýyorlar''
(flow). Hesabý çizit olarak belirtmenin bazý avantajlarý var, en önemlisi
çizit üzerinde direk otomatik türev alýnabilir, bkz. {\em Otomatik Türev
  Almak} yazýsý, ve bu þekilde gradyan hesaplarý kolay bir þekilde
yapýlabiliyor. Bir diðeri çizitin paralelleþtirme için doðal bir yapý
olmasý; çiziti istediðimiz þekilde bölerek parçalarý farklý mikroiþlemci
(CPU), ya da grafik iþlemci (GPU) üzerinde paralel bir þekilde
iþletebiliriz, mesela üstteki $f$ için $f(3,4)$ hesabý,

\includegraphics[width=20em]{tf_02.png}

þeklinde iki parçaya bölünebilir. 3 verilen soldaki parça kendi baþýna
hesabýný yaparken ayný anda 4 verilen diðer parça iþlemine devam
eder mesela. 

TF ile ilk hesap çizitimizi yaratalým. Üstteki örnek için 

\begin{minted}[fontsize=\footnotesize]{python}
import tensorflow as tf

x = tf.Variable(3, name="x")
y = tf.Variable(4, name="y")
f = x*x*y + y + 2
\end{minted}

Ýçinde $x,y,f$ düðümleri (node) olan bir çizit yaratýldý. Bu kadar! Fakat
anlamamýz gereken önemli bir nokta var, üstteki kodu iþletince halen bir
hesap yapmýþ olmuyoruz, sadece hesabý yaratacak çizit yapýsýný yaratmýþ
oluyoruz. Hesabýn kendisi için bir TF oturumu (session) açmak lazým, bu
oturum üzerinden deðiþkenleri baþlangýç deðerlerlerine eþitlenir, ve sonra
$f$ hesabý tetiklenir. Esas hesap bu þekilde ortaya çýkar.

\begin{minted}[fontsize=\footnotesize]{python}
sess = tf.Session()
sess.run(x.initializer)
sess.run(y.initializer)
result = sess.run(f)
print(result)
\end{minted}

\begin{verbatim}
42
\end{verbatim}

Eðer iþimiz bitti ise ve kaynaklarýn (bellek, iþlemci gibi) geri
dönüþümünü, serbest býrakýlmasýný istiyorsak oturumu kapatýrýz,

\begin{minted}[fontsize=\footnotesize]{python}
sess.close()
\end{minted}

Kodlama açýsýndan biraz daha temiz bir yol, 

\begin{minted}[fontsize=\footnotesize]{python}
with tf.Session() as sess:
    x.initializer.run()
    y.initializer.run()
    result = f.eval()
print result
\end{minted}

\begin{verbatim}
42
\end{verbatim}

Bu \verb!with! kullanýmý ile blok dýþýna çýkýlýnca kapatma iþlemi otomatik
olarak yapýlýyor. 

Nihai hesap için \verb!eval! çaðrýsý yapýldýðýný gördük, bu çaðrý aslýnda
herhangi bir düðümün hesaplanmasýný tetikleyebilir. Bu tetikleme sonrasýnda
TF bir düðümün hangi diðer düðümlere baðlý olduðuna bakarak çizitte önce o
düðümlerin hesabýný yapacaktýr, ve o çýktýlarý çizite göre birleþtirerek
nihai sonucu bulacaktýr. Mesela

\begin{minted}[fontsize=\footnotesize]{python}
w = tf.constant(3)
x = w + 2
y = x + 5
z = x * 3

with tf.Session() as sess:
    print 'y =', y.eval()
    print 'z =', z.eval()
\end{minted}

\begin{verbatim}
y = 10
z = 15
\end{verbatim} 

TF otomatik olarak $y$'nin $w$'ye, onun da $x$'e baðlý olduðunu gördü, önce
$w$'yi iþletti, sonra $y$'yi, ve onu da $z$ hesabý için kullandý.

Dikkat, TF onbellekleme yapmaz, yani üstteki kod $w,x$ hesabýný iki kere
yapar. Hesap çaðrýsý sonrasý deðiþken deðerleri muhafaza edilir (çünkü
onlar çizitin parçasý) fakat düðüm deðerleri yokolur.

TF'i bir anlamda numpy kütüphanesinin çizitli, çok iþlemcili versiyonu
olarak görebiliriz. Bir numpy matrisi üzerinde yapýlan pek çok iþlem TF ile
de yapýlabilir. Mesela bir matrisin tümü, herhangi bir ekseni bazýndaki
toplamlarý alttaki gibi alýnabiliyor,

\begin{minted}[fontsize=\footnotesize]{python}
x = tf.constant([[1., 1., 1.], [1., 1.,1.]])
c1 = tf.reduce_sum(x)
print tf.Session().run(c1)
c1 = tf.reduce_sum(x, 0) # y ekseni uzerinden toplam
print tf.Session().run(c1)
c2 = tf.reduce_sum(x, 1) # x ekseni uzerinden toplam
print tf.Session().run(c2)
\end{minted}

\begin{verbatim}
6.0
[ 2.  2.  2.]
[ 3.  3.]
\end{verbatim}

Lineer Regresyon

Þimdi toptan þekilde yapýlacak basit lineer regresyon hesabýný TF ile
yapalým. Regresyonu California emlak veri seti üzerinde iþleteceðiz, bu
veride bölge bazlý olarak ev sahiplerinin ortalama yaþý, geliri, gibi
deðiþkenler ile hedef deðiþkeni olan ev fiyatý kayýtlý. Hedef ve kaynak
deðiþkenler arasýndaki lineer iliþkiyi lineer regresyon ile
hesaplayabiliriz, tanýdýk toptan formül,

$\hat{\theta} = (X^TX )^{-1} X^T y $

TF ile veriye bir yanlýlýk (sadece 1 deðeri içeren yeni bir kolon) ekleyip
üstteki hesabý yapalým.

\begin{minted}[fontsize=\footnotesize]{python}
import tensorflow as tf
from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import StandardScaler
def reset_graph(seed=42):
    tf.reset_default_graph()
    tf.set_random_seed(seed)
    np.random.seed(seed)

housing = fetch_california_housing(data_home="/home/burak/Downloads/scikit-data")
print housing['data'].shape
print housing['target'][:5]

housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]
X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name="X")
y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name="y")
XT = tf.transpose(X)
theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)

with tf.Session() as sess:
    theta_value = theta.eval()
print 'theta'
print theta_value
\end{minted}

\begin{verbatim}
(20640, 8)
[ 4.526  3.585  3.521  3.413  3.422]
theta
[[ -3.68059006e+01]
 [  4.36796039e-01]
 [  9.45724174e-03]
 [ -1.07348330e-01]
 [  6.44418657e-01]
 [ -3.95741154e-06]
 [ -3.78908939e-03]
 [ -4.20193195e-01]
 [ -4.33070064e-01]]
\end{verbatim}

TF'in matris çarpýmý için \verb!matmul!, tersini alma için
\verb!matrix_inverse! çaðrýlarýný görüyoruz. 


\begin{minted}[fontsize=\footnotesize]{python}
reset_graph()

scaler = StandardScaler()
m, n = housing.data.shape
scaled_housing_data = scaler.fit_transform(housing.data)
scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]

X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name="X")
y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name="y")
theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name="theta")
y_pred = tf.matmul(X, theta, name="predictions")
error = y_pred - y
mse = tf.reduce_mean(tf.square(error), name="mse")
\end{minted}

Elle Hesaplanan Gradyan

\begin{minted}[fontsize=\footnotesize]{python}
n_epochs = 1000
learning_rate = 0.01

gradients = 2/np.float(m) * tf.matmul(tf.transpose(X), error)
training_op = tf.assign(theta, theta-(learning_rate*gradients))

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    for epoch in range(n_epochs):
        if epoch % 100 == 0: print("Epoch", epoch, "MSE =", mse.eval())
	sess.run(training_op)    
    best_theta = theta.eval()
    
print best_theta
\end{minted}

\begin{verbatim}
('Epoch', 0, 'MSE =', 9.1615429)
('Epoch', 100, 'MSE =', 0.71450073)
('Epoch', 200, 'MSE =', 0.56670469)
('Epoch', 300, 'MSE =', 0.55557162)
('Epoch', 400, 'MSE =', 0.54881161)
('Epoch', 500, 'MSE =', 0.54363626)
('Epoch', 600, 'MSE =', 0.53962916)
('Epoch', 700, 'MSE =', 0.53650916)
('Epoch', 800, 'MSE =', 0.53406781)
('Epoch', 900, 'MSE =', 0.53214705)
[[ 2.06855249]
 [ 0.88740271]
 [ 0.14401658]
 [-0.34770882]
 [ 0.36178368]
 [ 0.00393812]
 [-0.04269557]
 [-0.66145277]
 [-0.63752776]]
\end{verbatim}

Otomatik Hesap ile Gradyan

\begin{minted}[fontsize=\footnotesize]{python}
gradients = tf.gradients(mse, [theta])[0]
training_op = tf.assign(theta, theta-(learning_rate*gradients))

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    for epoch in range(n_epochs):
        if epoch % 100 == 0: print("Epoch", epoch, "MSE =", mse.eval())
	sess.run(training_op)
    
    best_theta = theta.eval()
    
print best_theta
\end{minted}

\begin{verbatim}
('Epoch', 0, 'MSE =', 9.1615429)
('Epoch', 100, 'MSE =', 0.71450061)
('Epoch', 200, 'MSE =', 0.56670463)
('Epoch', 300, 'MSE =', 0.55557162)
('Epoch', 400, 'MSE =', 0.54881167)
('Epoch', 500, 'MSE =', 0.5436362)
('Epoch', 600, 'MSE =', 0.53962916)
('Epoch', 700, 'MSE =', 0.53650916)
('Epoch', 800, 'MSE =', 0.53406781)
('Epoch', 900, 'MSE =', 0.53214717)
[[ 2.06855249]
 [ 0.88740271]
 [ 0.14401658]
 [-0.34770882]
 [ 0.36178368]
 [ 0.00393811]
 [-0.04269556]
 [-0.66145277]
 [-0.6375277 ]]
\end{verbatim}








\end{document}
